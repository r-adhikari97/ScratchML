{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17bed0fa-f5bf-48ab-9b29-c548912a564d",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "- Use of Sigmoid Function\n",
    "- Sigmoid  = 1 / 1 + e^(-x) : Provides Probablities as outputs\n",
    "- Calculating Error : Cross Entropy\n",
    "- Use of Gradient Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d139d81-9526-402c-80d7-8258e29e49d5",
   "metadata": {},
   "source": [
    "- **Steps** : **Training**\n",
    "    1. Initializing weights and bias as zero\n",
    "    2. For a data point predict result using y(cap) = 1 / 1 + e^(-x*w+b)\n",
    "    3. Calculate Error\n",
    "    4. Use Gradient Descent and set new weight + Biases\n",
    "    5. Repeat until convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947bb6c0-cbe8-4c81-b69c-4072f35aacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up math Library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd1719e7-e621-4a4c-a9e1-36a9a0a51d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(value):\n",
    "    return 1/(1+np.exp(-value))\n",
    "\n",
    "class LogisticRegressions:\n",
    "\n",
    "    # Setting up constructor\n",
    "    def __init__(self, lr=0.001, n_iter=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    # Training\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias =0\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "        \n",
    "            # Actual formula\n",
    "            linear_preds = np.dot(X, self.weights) + self.bias\n",
    "            predictions = sigmoid(linear_preds)\n",
    "\n",
    "            # Implementing Gradient Descent\n",
    "            dw = (1/n_samples)*np.dot(X.T, (predictions - y))*2\n",
    "            db = (1/n_samples)*np.sum(predictions - y)*2\n",
    "\n",
    "            # Updaing Weights\n",
    "            self.weights = self.weights - self.lr * dw\n",
    "            self.bias = self.bias - self.lr * db\n",
    "\n",
    "    # Testing\n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        # Actual formula\n",
    "        linear_preds = np.dot(X_test, self.weights) + self.bias\n",
    "        y_pred = sigmoid(linear_preds)\n",
    "        class_preds = [0 if y <= 0.5 else 1 for y in y_pred]\n",
    "        return class_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc63e3c8-2e6b-4267-bf14-3d6763a90f37",
   "metadata": {},
   "source": [
    "## Setting up Learning Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8cfecb5-d088-4204-952f-a10c15147990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_optimizer():\n",
    "    learning_rates = np.arange(0.000, 0.1 , 0.001)\n",
    "    best_acc = 0\n",
    "    best_lr = 0\n",
    "    \n",
    "    for rate in learning_rates:\n",
    "        model = LogisticRegressions(lr=rate)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        acc_score = accuracy(preds, y_test)\n",
    "        \n",
    "        # Checking scores\n",
    "        if acc_score > best_acc:\n",
    "            best_acc = acc_score\n",
    "            best_lr = rate\n",
    "\n",
    "    return best_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0615bb8-8717-401e-b4bd-2fa3e6f60601",
   "metadata": {},
   "source": [
    "## Setting Up Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74a20198-7c7d-438a-9201-7ee081bfa018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a15e5a75-4996-44e8-a054-3a3f2db80f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_breast_cancer()\n",
    "X,y = dataset.data, dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6001b247-bf4d-404a-9987-6f9d5440e595",
   "metadata": {},
   "source": [
    "## Setting Up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a6ab560-eaa7-4648-abf8-2da455824a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aviat\\AppData\\Local\\Temp\\ipykernel_2084\\1282676904.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-value))\n"
     ]
    }
   ],
   "source": [
    "lr_clf =LogisticRegressions()\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65acf74-965b-417e-b329-04265c3ce76b",
   "metadata": {},
   "source": [
    "## Setting up Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "24a6c99a-cdab-4fc4-b0b4-1a08118804f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy (preds, y_test):\n",
    "    return np.sum(preds == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81124bce-49c0-462e-b9be-41545ce0ef83",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad24327d-0884-46ff-8272-d950102cbcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model : 0.9210526315789473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aviat\\AppData\\Local\\Temp\\ipykernel_2084\\1282676904.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-value))\n"
     ]
    }
   ],
   "source": [
    "preds = lr_clf.predict(X_test)\n",
    "print(f\"Accuracy of our model : {accuracy(preds, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66767d1b-7232-40ac-bef7-c8a82e292a54",
   "metadata": {},
   "source": [
    "## Optimizing Model using Gradient Descent learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "071ae5af-635a-4f92-bf50-0eefb497ca0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aviat\\AppData\\Local\\Temp\\ipykernel_2084\\1282676904.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-value))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model : 0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "lr_clf =LogisticRegressions(lr=learning_rate_optimizer())\n",
    "lr_clf.fit(X_train, y_train)\n",
    "preds = lr_clf.predict(X_test)\n",
    "print(f\"Accuracy of our model : {accuracy(preds, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f313a3-29f5-4f66-b6bb-35b214aca8ae",
   "metadata": {},
   "source": [
    "## Comparing with other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8b5dc677-4440-479d-95e5-487abef51f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a78cb1f-1a8a-4f45-bd2a-9450fdf3e85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Sklearn model : 0.9385964912280702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(penalty=None, solver='lbfgs')\n",
    "LR.fit(X_train, y_train)\n",
    "preds = LR.predict(X_test)\n",
    "print(f\"Accuracy of Sklearn model : {accuracy(preds, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34310465-12b3-40a2-8f9e-bc232a976160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
